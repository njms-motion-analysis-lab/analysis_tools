<img width="579" alt="Pasted Graphic 2" src="https://user-images.githubusercontent.com/15318220/224393092-5babe62d-46e0-45cd-823e-75b58c1d3688.png">



# Installation

## Remote
* VPN Access: https://it.rutgers.edu/virtual-private-network/
* Amarel Access: https://oarc.rutgers.edu/resources/amarel/
* Python and package manager (See Amarel docks above for installation instructions)

## Local
  * Set up command line tools (Mac)
    * https://www.freecodecamp.org/news/install-xcode-command-line-tools/
  * Download text editor (I recommend VS Code)
  * Get homebrew package manager (PIP for Python works too)
      * https://brew.sh (nb: your password will not show up when prompted)
  * Install python python3 from home-brew with `brew install python3`
  * Install python packages `pip install -r requirements.txt`
  * If you encounter an errror, try installing an indivudal package manually without specifying the version


# Data

## Ingestion
  * The current data involves sensor coordinates while patients or healthy controls performed ADLs; it can be found on the lab motion analysis  Drive: https://drive.google.com/drive/u/0/folders/1bBezhJiFSPTo9fLG1i1jP0qqsuWlGBCj
  * After downloading the folder of choice, move it to the `/raw_data` folder within this repo.

## Database
  * To create the SQL tables, use the following commands:
    `from migrations.legacy_table import Table`
    `Table.create_tables()`
    `Table.update_tables()`

## Models
  * Running the command `python3 legacy_importer.py` will ingest the contents of the `raw_data` folder and create objects according to the schemas in the SQL database.
  * See the picture below for a rough diagram (TODO)


Right 
* Ingestion
    * Local
    * Amarel
* Model generation
    * ERD
* Feature Extraction—TS fresh params

Training
* Path to train
    * Default vs norm vs abs
* What is happening?
    * Models used
        * Hyperparams for grid search
    * Sensors used
* Code pathway
    * Train test split vs Leave one out
        * K-fold
        * To change
    * Parts of each i.e. object
        * 
    * GridSearch params
    * Fix odd test
* Metrics
    * Storing
    * Logging
    * Shapley values
    * Viewing
        * Beeswarm
        * Heatmap

# What is this?
This repository is a collection of tools designed to make it easier to visualize and interpret results from motion analysis experiments. Some of the functions included in this collection are:
  * [Generating CSVs from NPY files](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/csv_generator.py#L9), 
  * [Getting sub motions across x,y, and z axes](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/exp_motion_sample_trial.py#L43)
  * [Eliminating extranous submotions](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/motion_filter.py#L32)
  * Plotting sub-motions (requires this [NPY Viewer](https://github.com/csmailis/NPYViewer) project right now
  * [Gathering statistics](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/viewer.py#L44) on motion and [normalizing](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/exp_motion_sample_trial.py#L23) data
  * [Returning normalized, and filtered to CSV form](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/viewer.py#L71)

# How do I set this up? 





(NB: Old way to look at data but still works for install)
  Now try running the program with a comment like ```python3 viewer.py 'wrist' 'l' 'a' 'z'``` You will almost certainly get an error message
  but that's ok. It probably means some sort of package is not installed. The required packages will likely change a bit with time but an easy way to handle them is to read the error message and then present it to a tool like [ChatGPT](https://chat.openai.com) and follow its recommendations. It will offer a more elaborate and customized version of the instruction below.

  6. Follow prompts from terminal if something isn’t installed
      i.e. missing package numpy => `brew install numpy` or `pip install nummpy`

  7. Eventually the code will run without an error but also without loading any data. At this point you'll want to download the [dataset](http://drive.google.com/drive/u/3/folders/1bBez…)
  8. Move the dataset directory so that it is on the same level as the python files here, that way the program can [find the data](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/viewer.py#L27)


# How do look at the data? 

The main entry point for this project is the viewer.py file. This script reads the .npy files and generates models and associations. To explore the data, you can drop a Python debugger around the end of the viewer.py file by adding the line import pdb; pdb.set_trace().

To get started, you can run the following command:
```
python3 importer.py 
```
This will bring you to a debugger that will allow you to peruse the current models. That said, when you quit the debugger, the db will be wiped. This "feature" will go away when we're totally sure about everything :)

# Some helpful methods...


* `.all()` => `GradientSet.all()`
* `.where()` => `GradientSet.where(trial_id=884)`
* `.create_subgradients()` (on GradientSet instance), this will create sub motions based on zero value crossings. => `GradientSet.where(trial_id=884)[0].create_subgradients()`

SubGradient Example: 
```
(Pdb) sg = GradientSet.where(trial_id=884)[0].create_subgradients()
(Pdb) pp sg[-1]
<models.sub_gradient.SubGradient object at 0x43de422f0>
(Pdb) pp sg[-1].attrs()
Attributes:
id: 37
created_at: 2023-04-10 13:10:17.583353
updated_at: 2023-04-10 13:10:17.583354
name: lfhd_x
valid: 0
matrix: b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00\x8c\x00\x94.'
gradient_set_id: 884
gradient_set_ord: 36
start_time: 1020
stop_time: 1025
mean: -0.02329880347760747
median: -0.02569447478447273
stdev: 0.02169755398101877
```

On SubGradient:

* `.gradient_set()` (gets parent object)
* `.grad_matrix()` (corresponding matrix from parent motion)
* `.pos_matrix()` (corresponding position matrix)

This command tells the code to look at results related to the left wrist, sensor A, and in the Z-direction. You can try different wrist sensors as well. Currently, the available sensors are limited to the wrist, but other sensors will be added [here](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/constants.py) soon.



  




