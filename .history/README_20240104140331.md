<img width="579" alt="Pasted Graphic 2" src="https://user-images.githubusercontent.com/15318220/224393092-5babe62d-46e0-45cd-823e-75b58c1d3688.png">



# Installation

## Remote
* VPN Access: https://it.rutgers.edu/virtual-private-network/
* Amarel Access: https://oarc.rutgers.edu/resources/amarel/
* Python and package manager (See Amarel docks above for installation instructions)

## Local
  * Set up command line tools (Mac)
    * https://www.freecodecamp.org/news/install-xcode-command-line-tools/
  * Download text editor (I recommend VS Code)
  * Get homebrew package manager (PIP for Python works too)
      * https://brew.sh (nb: your password will not show up when prompted)
  * Install python python3 from home-brew with `brew install python3`
  * Install python packages `pip install -r requirements.txt`
  * If you encounter an errror, try installing an indivudal package manually without specifying the version


# Data

## Ingestion
  * The current data involves sensor coordinates while patients or healthy controls performed ADLs; it can be found on the lab motion analysis  Drive: https://drive.google.com/drive/u/0/folders/1bBezhJiFSPTo9fLG1i1jP0qqsuWlGBCj
  * After downloading the folder of choice, move it to the `/raw_data` folder within this repo.

## Database
  * To create the SQL tables, use the following commands:
    `from migrations.legacy_table import Table`
    `Table.create_tables()`
    `Table.update_tables()`

## Models
  * Running the command `python3 legacy_importer.py` will ingest npy files in the `raw_data` folder and create objects according to the schemas in the SQL database.
  * See the picture below for a rough diagram (TODO)
  * Additionally, this will break up motion for each sensor and trial into gradients (velocity) and subgradients based on zero value crossing. We also normalize subgradients gradients by length and store those.
  * From here, we use the `ts_fresh` package to extract features from sub gradients, normalized sub gradients, and the absolute value of sub gradients. Currently we are getting a comprehensive set of features. (TODO, show features and param serialization)
  * Running `python3 progress.py` will give a summary of each patient, as well as the tasks they completed and the trials measured and gradients captured.

## Training
* As of now, most entrypoints for training models are in `mini_console.py` this file imports many of the models. By adding debuggers, train as well as debug the activities and models of choice.

* Training classes are stored in the /prediction_tools folder and include the following 
  1. MultiPredictor--parent class for Predictor, has methods for displaying aggregate stats and training entry points.
  2. Predictor--set of training models for a given sensor_id and cohort_id. Predictor classes gather a patient cohort as well as params for normalization and abs value to train on relevent sensor data. By default this trains all models.
  3. PredictorScore--generated by Predictor model and contains the SHAP values for its parent predictor. This model also contains logic for generating heatmaps.

* Guide for training

  1. Find the set of patients and sensors by finding or creating a MultiPredictor object. For example,
      * to fetch results of block tasks...
      >mpa = MultiPredictor.where(cohort_id=1, task_id=3)[0]
      * you can view attributes of the object with the `mpa.attrs()`
      * you can view stats, like accuracy with `mpa.get_acc()`
      * you can view prior training runs with `mpa.get_all_preds()`
      * for example, 
      >(Pdb) pp len(mpa.get_all_preds())
      >30
      * Since we have 10 sensors, this (likely) means we have a set of predictor for regular stats, normalized stats, and absolute value stats.
      * if no predictors are present we can call `gen_scores_for_sensor` on the MultiPredictor (link: https://vscode.dev/github/stephen3292/motion_analysis/blob/6629205fcf92c9e3849ae983b159baeaaaee8639/prediction_tools/legacy_multi_predictor.py#L217-L226). By default this gets the 10 sensors shown at the top of the file and generates Predictor models for each.

  2. Call `.train_from()` or, if retraining an existing predictor, `retrain_from()`. (link: https://vscode.dev/github/stephen3292/motion_analysis/blob/6629205fcf92c9e3849ae983b159baeaaaee8639/prediction_tools/legacy_predictor.py#L412-L429)

    * This method first fetches a dataframe representing ts_fresh statistics for that sensor location (link: https://vscode.dev/github/stephen3292/motion_analysis/blob/6629205fcf92c9e3849ae983b159baeaaaee8639/prediction_tools/legacy_predictor.py#L470-L513)

    * This also generates dataframes representing ts fresh statistics from the coordinate non dominant task and sensor (i.e. right wrist dom => left wrist non dom)

    * The `generate_dataframe` method has logic to manually switch for sensors for left hand dominant patients: https://vscode.dev/github/stephen3292/motion_analysis/blob/6629205fcf92c9e3849ae983b159baeaaaee8639/prediction_tools/legacy_predictor.py#L337-L339

    * After getting the dataframe, we have logic to shrink the combined dataframe to roughly 50 x 50 (25 patients x 2 dominance levels by 50 selected features). Feature selection logic: https://vscode.dev/github/stephen3292/motion_analysis/blob/6629205fcf92c9e3849ae983b159baeaaaee8639/prediction_tools/legacy_predictor.py#L568
    


  
https://vscode.dev/github/stephen3292/motion_analysis/blob/6629205fcf92c9e3849ae983b159baeaaaee8639/prediction_tools/legacy_multi_predictor.py#L217-L226
Right 
* Ingestion
    * Local
    * Amarel
* Model generation
    * ERD
* Feature Extraction—TS fresh params

Training
* Path to train
    * Default vs norm vs abs
* What is happening?
    * Models used
        * Hyperparams for grid search
    * Sensors used
* Code pathway
    * Train test split vs Leave one out
        * K-fold
        * To change
    * Parts of each i.e. object
        * 
    * GridSearch params
    * Fix odd test
* Metrics
    * Storing
    * Logging
    * Shapley values
    * Viewing
        * Beeswarm
        * Heatmap

# What is this?
This repository is a collection of tools designed to make it easier to visualize and interpret results from motion analysis experiments. Some of the functions included in this collection are:
  * [Generating CSVs from NPY files](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/csv_generator.py#L9), 
  * [Getting sub motions across x,y, and z axes](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/exp_motion_sample_trial.py#L43)
  * [Eliminating extranous submotions](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/motion_filter.py#L32)
  * Plotting sub-motions (requires this [NPY Viewer](https://github.com/csmailis/NPYViewer) project right now
  * [Gathering statistics](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/viewer.py#L44) on motion and [normalizing](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/exp_motion_sample_trial.py#L23) data
  * [Returning normalized, and filtered to CSV form](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/viewer.py#L71)

# How do I set this up? 





(NB: Old way to look at data but still works for install)
  Now try running the program with a comment like ```python3 viewer.py 'wrist' 'l' 'a' 'z'``` You will almost certainly get an error message
  but that's ok. It probably means some sort of package is not installed. The required packages will likely change a bit with time but an easy way to handle them is to read the error message and then present it to a tool like [ChatGPT](https://chat.openai.com) and follow its recommendations. It will offer a more elaborate and customized version of the instruction below.

  6. Follow prompts from terminal if something isn’t installed
      i.e. missing package numpy => `brew install numpy` or `pip install nummpy`

  7. Eventually the code will run without an error but also without loading any data. At this point you'll want to download the [dataset](http://drive.google.com/drive/u/3/folders/1bBez…)
  8. Move the dataset directory so that it is on the same level as the python files here, that way the program can [find the data](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/viewer.py#L27)


# How do look at the data? 

The main entry point for this project is the viewer.py file. This script reads the .npy files and generates models and associations. To explore the data, you can drop a Python debugger around the end of the viewer.py file by adding the line import pdb; pdb.set_trace().

To get started, you can run the following command:
```
python3 importer.py 
```
This will bring you to a debugger that will allow you to peruse the current models. That said, when you quit the debugger, the db will be wiped. This "feature" will go away when we're totally sure about everything :)

# Some helpful methods...


* `.all()` => `GradientSet.all()`
* `.where()` => `GradientSet.where(trial_id=884)`
* `.create_subgradients()` (on GradientSet instance), this will create sub motions based on zero value crossings. => `GradientSet.where(trial_id=884)[0].create_subgradients()`

SubGradient Example: 
```
(Pdb) sg = GradientSet.where(trial_id=884)[0].create_subgradients()
(Pdb) pp sg[-1]
<models.sub_gradient.SubGradient object at 0x43de422f0>
(Pdb) pp sg[-1].attrs()
Attributes:
id: 37
created_at: 2023-04-10 13:10:17.583353
updated_at: 2023-04-10 13:10:17.583354
name: lfhd_x
valid: 0
matrix: b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00\x8c\x00\x94.'
gradient_set_id: 884
gradient_set_ord: 36
start_time: 1020
stop_time: 1025
mean: -0.02329880347760747
median: -0.02569447478447273
stdev: 0.02169755398101877
```

On SubGradient:

* `.gradient_set()` (gets parent object)
* `.grad_matrix()` (corresponding matrix from parent motion)
* `.pos_matrix()` (corresponding position matrix)

This command tells the code to look at results related to the left wrist, sensor A, and in the Z-direction. You can try different wrist sensors as well. Currently, the available sensors are limited to the wrist, but other sensors will be added [here](https://github.com/njms-motion-analysis-lab/analysis_tools/blob/master/constants.py) soon.



  




